{"meta":{"title":"鱼先生的博客","subtitle":"","description":"","author":"鱼先生","url":"http://yoursite.com","root":"/"},"pages":[],"posts":[{"title":"Python 学习入门与实践 - 变量和简单数据类型","slug":"Python-学习入门与实践","date":"2020-05-23T15:24:21.000Z","updated":"2020-05-24T07:54:53.747Z","comments":true,"path":"2020/05/23/Python-学习入门与实践/","link":"","permalink":"http://yoursite.com/2020/05/23/Python-%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E4%B8%8E%E5%AE%9E%E8%B7%B5/","excerpt":"","text":"今天开始学习 《Python 学习入门与实践》 这本书。 书一开始是如何安装python，这块内容可以跳过。然后开始介绍Variable. 字符串：修改单词大小写，name.title(), title()函数以首字母大写的方式显示每个单词。name.uppoer() and name.lower(). 方法lower（）很有用，很多时候你无法根据用户来提供正确的大小写。 合并（拼接）字符串：Python 用加号（+）来合并字符串，full_name = first_name + ‘ ‘ + last_name 合并字符串的方法称为 拼接。message = ‘Hello, ‘+full_name.title() + ‘!’ 使用字符标或换行符来添加空白：添加空白用 \\t,print(‘\\tpython’)换行用：\\n,print(‘Language:\\npython\\nC\\vJavascript’)或者混合使用：\\n\\t 找到字符串开头或结尾多余的空白，删除这些多余的空格，用rstrip(): favrourite_language = ‘python ‘, favrourite_language.rstrip() 永久删除字符串中的空白，需将存量返回到变量：favrourite_language = favrourite_language.rstrip() 可以单独踢出开头空白，结尾空白或同时提出：lstrip() - 剔除开头，rstrip() - 剔除结尾, strip() - 同时剔除。 使用字符串时，避免语法错误：例如 单引号，双引号，撇号的使用。 数字：整数，浮点数：python 将带小数点的数字都称为浮点数。暂时忽略多余小数位数即可。 使用 str()避免类型错误：age=23,pytohn 无法print(),因为它不知道如何解读一个值为整数（int）。像这样在字符串中使用整数时，需要显示地指出你希望python 将这个整数作为字符串，可调用函数str(). age = str(age),print(). 注释：注释用（#）号标识。主要目的是阐述代码要做什么。 理念：简约而清晰。","categories":[],"tags":[]},{"title":"Python-learning-6","slug":"Python-learning-6","date":"2020-05-13T13:28:07.000Z","updated":"2020-05-16T10:35:01.643Z","comments":true,"path":"2020/05/13/Python-learning-6/","link":"","permalink":"http://yoursite.com/2020/05/13/Python-learning-6/","excerpt":"","text":"今天继续python 的学习： 22、serial_scanner.py 端口扫描 这个练习我放弃了。没懂这个究竟有什么用。 21、tweeter.py 用这个脚本发送Twitter 这个练习是用 api 来 post Twitter，但是我没有账号，所以无法实操。搜集了一下information，可以参考这个 video 来做：https://www.youtube.com/watch?v=0FOUFF4q14A 我本来想搞个微博的，新浪微博的确有api借口，后来看了半天，不是要这个身份验证，要么就是要完善那个个人信息。于是放弃了。 20、testlines.py 这个脚本用来读取文件并打印100行 def write_to_file(filename, txt): with open(filename, ‘w’) as file_object: s = file_object.write(txt) write_to_file(‘server_list.txt’, ‘It is suppose to write 100 lines.’) 这个就是 打开一个文件，然后修改书写这个文件。 19、 script_listing.py 这个脚本用来遍历指定目录以及子目录下面所有的文件 import os target = ‘/Users/Yu/Desktop/Hexo’file = open(‘big-listing.txt’,’w’)for root,dirname,files in os.walk(target): for x in files: file.write(root + x )file.close() 不单可以打印出子目录和文件，还可以把它们存储到一个file 里面。这个练习主要是 使用os.walk 这个 function 来遍历目录里面的文件。 [get_youtube_view.py] 这个标本用来统计 youtube 视频的观看次数，有时我也用来统计歌曲的播放次数。 这个压根就不是什么统计播放次数，是一个自动大刷器。无限刷观看次数和播放次数的吧。 import time from selenium import webdriver count = int(input(“Number of times to be repeated: “))url = input(“Enter the URL : “)print(“Length of video:”)minutes = int(input(“Minutes “))seconds = int(input(“Seconds “)) refreshrate = minutes * 60 + secondsdriver = webdriver.Chrome() if url.startswith(“https://“): driver.get(url)else: driver.get(“https://“ + url) for i in range(count): # Sets the page to refresh at the refreshrate. time.sleep(refreshrate) driver.refresh() 17、script_count.py 统计目录下不同脚本 我们来换一个需求吧，统计某个目录下，以某个结尾的文件数量。 import osdir=”/Users/Yu/Desktop/Mywebsite”m=0 for root,dirs,files in os.walk(dir): for file in files: x = file.split(‘.’) if x[-1] == ‘html’: m=m+1 print(m)","categories":[],"tags":[]},{"title":"Python-learning-5","slug":"Python-learning-5","date":"2020-04-27T08:36:44.000Z","updated":"2020-05-10T14:53:00.269Z","comments":true,"path":"2020/04/27/Python-learning-5/","link":"","permalink":"http://yoursite.com/2020/04/27/Python-learning-5/","excerpt":"","text":"今天我们继续学习python。 26、 calculator.py 使用 Python 的eval()函数实现计算器关于这个练习，一开始我知识以为 设定几个 function def add() def divide() def substract() 等等，然后去编译就行了。后来我才了解到，其实只要使用 eval（）这个函数，就可以直接得出计算结果了。 def calculator(x): results = eval(x) print(results) x=input(‘Enter your calculation request: ‘) calculator(x) 25、timymodule.py 一个更好的易于使用的timeit模块标准答案完全没看懂。我觉得我放弃这个练习了。但是 我学习到了 什么是 timeit 模块。 import timeitprint(timeit.timeit(‘’’ def calculator(x): results = eval(x) print(results)calculator(‘10*10’)‘’’,number=100)) 使用 timeit模块可以知道运行这个 function 花费计算机多少时间。 24、xkcd_downloader.py 下载最新的XKCD漫画，然后将他们放入comics新文件夹python 爬虫基础练习，一步一步分解分析。 首先，可以使用 urllib.request.urlretrieve 将图片下载下来，然后放入指定文件夹内。可以分两步来，生成自定文件夹，以及，抓取到图片的 url，难点在于如何每次都自动的抓到图片url 而不是手动去页面端copy image address. 生成文件夹比较简单： comic_location = os.getcwd() + ‘/comics/‘ # checks if save location exists else createsif not os.path.exists(comic_location): os.makedirs(comic_location) # creates final comic location including name of the comiccomic_location = comic_location + comic_name 下面通过 xpath 抓取对应 image url首先转化 page content 需要使用 html.fromstring(page.content),(We need to use page.content rather than page.text because html.fromstring implicitly expects bytes as input.)tree now contains the whole HTML file in a nice tree structure which we can go over two different ways: XPath and CSSSelect. In this example, we will focus on the former. 然后用xpath 抓出id //[@id=”comic”]/img，经过分析，image url 在 src 后面，所以变成 “.//[@id=’comic’]/img/@src” 然后 前面还要加一个 httpsimage_src = “https:” + str(image_src)code 如下： import osimport urllib.requestimport requestsfrom lxml import html page = requests.get(“https://www.xkcd.com&quot;) tree = html.fromstring(page.content) image_src = tree.xpath(“.//*[@id=’comic’]/img/@src”)[0] image_src = “https:” + str(image_src) # gets comic name from the image src urlcomic_name = image_src.split(‘/‘)[-1] # save location of comiccomic_location = os.getcwd() + ‘/comics/‘ # checks if save location exists else createsif not os.path.exists(comic_location): os.makedirs(comic_location) # creates final comic location including name of the comiccomic_location = comic_location + comic_name # downloads the comicurllib.request.urlretrieve(image_src, comic_location) 23、CountMillionCharacter.py And CountMillionCharacter2.0.py 统计文本字符读取文档，然后使用split function 分割出单个word. split(), string.split(separator, maxsplit) 如果不放入值，默认是空格作为分割。或者可以放入特定的值来分割。 import os infile=open(‘/Users/Yu/Desktop/server_list.txt’,’r’,encoding=’utf-8’)data = infile.read()numberOfword=len(data.split())print(numberOfword) To be continued…","categories":[],"tags":[]},{"title":"Python - learning -4","slug":"Python-learning-4","date":"2020-04-20T08:04:55.000Z","updated":"2020-04-24T09:29:47.208Z","comments":true,"path":"2020/04/20/Python-learning-4/","link":"","permalink":"http://yoursite.com/2020/04/20/Python-learning-4/","excerpt":"","text":"今天继续学习Python。 11、nslookup_check.py 打开文件server_list.txt，然后nslookup。 一开始我压根就不知道 nslookup 做什么的，反正干就是了。后来查了一下，nslookup命令用于查询DNS的记录，查看域名解析是否正常，在网络故障的时候用来诊断网络问题。 另外，下面代码运行需要加上 shell = True,不然无法运行，也不知道为什么。我有查说，只有 Windows需要加，但是 我是Mac啊。 import subprocess # Import the subprocess moduleimport osfor server in open(‘server_list.txt’): subprocess.Popen(‘nslookup ‘ + server,shell=True) # Run the nslookup command for each server in the list 12、osinfo.py 检查系统信息这个 practice 代码是抄的。我不太懂为什么要这样来看系统电脑信息，直接去电脑里面看就好了呀。import platform as pl profile = [ ‘architecture’, ‘linux_distribution’, ‘mac_ver’, ‘machine’, ‘node’, ‘platform’, ‘processor’, ‘python_build’, ‘python_compiler’, ‘python_version’, ‘release’, ‘system’, ‘uname’, ‘version’,] class bcolors: HEADER = ‘\\033[95m’ OKBLUE = ‘\\033[94m’ OKGREEN = ‘\\033[92m’ WARNING = ‘\\033[93m’ FAIL = ‘\\033[91m’ ENDC = ‘\\033[0m’ BOLD = ‘\\033[1m’ UNDERLINE = ‘\\033[4m’ for key in profile: if hasattr(pl, key): print(key + bcolors.BOLD + “: “ + str(getattr(pl, key)()) + bcolors.ENDC)13、ping_servers.py 根据指定的参数，ping 应用组关联的服务器。这个practice 我理解实际就是ping下服务器看它是否 work，标准答案很复杂，实际简单点来说如下： import os for server in open(‘server_list.txt’): response = os.system(‘ping -c 3 ‘ + server) if response == 0: print(server, ‘is good.’) else: print(server,’is bad.’)基本来说 有反馈就是work，没反馈就不work。。ping -c 3 代表 ping 3 下。 14、ping_subnet.py ping 子网这题我放弃了，我觉得和13题没什么区别。顺便了解了一下什么是子网： “网络上，数据从一个地方传到另外一个地方，是依靠 IP 寻址。从逻辑上来讲，是两步的。第一步，从 IP 中找到所属的网络，好比是去找这个人是哪个小区的；第二布，再从 IP 中找到主机在这个网络中的位置，好比是在小区里面找到这个人。第一步中的网络，就称之为「子网」（Subnet）。从逻辑上来讲，一般同一子网（Subnet）是使用相同的网关。就好比，一个小区的入口。 作者：Dion链接：https://www.zhihu.com/question/21064101/answer/17056026来源：知乎著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。” 接下来，我有个决定，跳到最后一题开始吧，因为第15题我感觉真的用不到。 31、SimpleStopWatch.py 使用 time 模块简单实现秒表功能import timeprint(‘Press ENTER to begin, Press Ctrl + C to stop’)while True: try: input(‘Please Enter’) # For ENTER. Use raw_input() if you are running python 2.x instead of input() starttime = time.time() print(‘Started’) while True: print(‘Time Elapsed: ‘, round(time.time() - starttime, 0), ‘secs’, end=”\\r”) time.sleep(1) # 1 second delay except KeyboardInterrupt: print(‘Stopped’) endtime = time.time() print(‘Total Time:’, round(endtime - starttime, 2), ‘secs’) break input() 就是回车后跳到下一行命令启动，time.time() 就是拿到现在当下的时间，然后利用 round（）函数两个相减去，里面0 或 2 表示精确到小数点几位数。exception KeyboardInterrupt,这个一般默认user 输入 Control C 30、site_health.py 检查远程服务器的健康情况这个主要还是考察request 的用法： import requestsimport urllib.request code=requests.get(“https://yuhuang819.github.io/&quot;).status_codeprint(code) status=urllib.request.urlopen(“https://yuhuang819.github.io/&quot;).codeprint(status) 我们期望反馈回来的是200，因为表示成功处理了请求的状态码。 200(成功)服务器已成功处理了请求。 通常，这表示服务器提供了请求的网页。 29、youtube.py 输入一首歌曲名称然后获取最佳匹配歌曲并播放刚拿到这个题目，我感觉还挺有意思的。考察爬虫基础知识了。 编写这个项目的时候，学习了.format()的用法。The format() method formats the specified value(s) and insert them inside the string’s placeholder. 同时，这里还有一个用法是 x for x in 的用法。new_list = [expression for member in iterable] 同时还学习了 new_list = [expression for member in iterable (if conditional)] 例如： sentence = ‘the rocket came back from mars’vowels = [i for i in sentence if i in ‘aeiou’] 抓歌曲代码如下：import requests,sys,webbrowser,bs4 query =[x for x in input(‘Enter the name with comma: ‘).split(‘,’)]url = ‘https://www.youtube.com/results?search_query={}&#39;search_url = []i=0for i in range(0,len(query)): search_url = url.format(query[i]) webbrowser.open_new(search_url) 28、cricket_live_score 使用BeautifulSoup提供板球直播分数关于这个联系，其实就是爬虫的应用。到相应网站去抓取数据，然后从抓取的数据中，清洗出自己想要的数据，然后打印出来。标准答案中，还使用了win0toast 这个module，可以直接跳出一个notification，但是我是用的是 Macbook，好像没发使用这个module。但是我是用 terminal-notifier 也可以在Mac 中实现这个功能，我们来试一下。另外板球比分我就不需要了。我来抓一下篮球比分吧。 from urllib import request import bs4 # Beautiful Soup for Web Scrapingimport os url = “https://nba.hupu.com/&quot;team_name = []score_table = []sauce = request.urlopen(url).read()soup = bs4.BeautifulSoup(sauce, “lxml”)for team in soup.find_all(‘span’,attrs={‘class’:’team-name’}): team_name.append(team.text) for score in soup.find_all(‘span’,attrs={‘class’:’team-rate team-rate-highlight’}): score_table.append(score.text) The notifier functiondef notify(title, subtitle, message): t = ‘-title {!r}’.format(title) s = ‘-subtitle {!r}’.format(subtitle) m = ‘-message {!r}’.format(message) os.system(‘terminal-notifier {}’.format(‘ ‘.join([m, t, s]))) Calling the functionnotify(title = ‘NBA Regular Game’, subtitle = team_name[0] + score_table[0] + ‘ ‘ + team_name[2] + score_table[2] + ‘ ‘ + team_name[4] + score_table[4] + ‘ ‘ + team_name[6] + score_table[6], message = team_name[1] + score_table[1] + ‘ ‘ + team_name[3] + score_table[3] + ‘ ‘ + team_name[5] + score_table[5] + ‘ ‘ + team_name[7] + score_table[7]) 27、Google_News.py 使用BeautifulSoup通过新闻链接获取新闻标题 Google news 用不了，我直接抓同花顺的股票新闻吧。 from urllib import requestimport ssl import bs4 # Beautiful Soup for Web Scraping url = request.Request(“http://www.10jqka.com.cn/&quot;,headers={&#39;User-Agent&#39;:&#39;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.163 Safari/537.36’})sauce = request.urlopen(url).read()soup = bs4.BeautifulSoup(sauce, “lxml”)news_box_1 = soup.find(‘div’,{‘class’:’tab-container’})news_box_2 = soup.find(‘div’,{‘class’:’tab-container’}) print(news_box_1.text)print(news_box_2.text) 考察beautifulsoup 的用法，如何使用 div class 定位来抓取自己想要的信息。一开始抓的时候报错403 是因为没有添加user agent，在这里也一并学习了。 To be continued.","categories":[],"tags":[]},{"title":"就没有比天猫CEO绯闻更重要的话题讨论了吗","slug":"空虚的中国人","date":"2020-04-19T15:14:36.000Z","updated":"2020-04-19T15:33:11.743Z","comments":true,"path":"2020/04/19/空虚的中国人/","link":"","permalink":"http://yoursite.com/2020/04/19/%E7%A9%BA%E8%99%9A%E7%9A%84%E4%B8%AD%E5%9B%BD%E4%BA%BA/","excerpt":"","text":"这几天，网上最热的话题，应该要属天猫ceo的绯闻事件。天猫总裁太太手撕网红张大奕，各大平台舆论哗然，有的是议论事情本身，有的是议论资本操纵舆论，而有的可能就是吃瓜罢了。 我觉得我们国家和社会有更多东西值得议论，但是我们的人民或网民却不会去议论或可以避开或者根本就不知道。我觉得天猫ceo这个事情的议论，根本就不会使得我们的社会变得更好。有很多更重要的事情，值得人民去讨论，而且作为一个合法公民，更应该为此贡献出一份信息和意见。 任大炮的失联究竟是什么原因，他是否发表了某些观点或看法导致失去联系。B站网红郭杰瑞作为一个自媒体人，到纽约各大医院拍摄并且采访，同时拍摄了纽约停尸间的画面，并引起广泛议论。郭杰瑞将视频放上YouTube 和 B 站，同时中国官方媒体还和郭杰瑞合作，引入郭杰瑞拍摄的视频，在国家公众号上播出宣传。我们国家的自媒体人员，在疫情期间去武汉采访并跟踪拍摄，国内没有任何媒体看得到他们拍摄的视频。只有在国外 YouTube 网站可以看到他们的视频。为什么，我们很乐于引用郭杰瑞拍摄的美国纽约新冠期间的视频，而我们在中国却看不到除了官方媒体以外其他人发布的视频，同时那些自媒体人还消失了。李文亮医生得到了政府有关部门的道歉，这个点赞，给人民和李医生家人一个交待。但是为了避免李医生这样的悲剧再次发生，我们是否应该立法对于舆论的监管应该在一个可见的法治体制下运行。而不是一味的打压，列出清晰的立法，清楚告知民众什么可以说，什么不可以说。 上述我说的三个问题，就没人关心一下吗？未来你们要的民主投票，必须在公民独立思考的基础上建立起来。国家的立法，社会的制度和社区和谐精神社会，跟每一个人的讨论和想法都有关系。最红的话题是天猫ceo的八卦是无法强国的。","categories":[],"tags":[]},{"title":"Python - learning -3","slug":"Python-learning-3","date":"2020-04-13T15:36:19.000Z","updated":"2020-04-19T15:13:51.437Z","comments":true,"path":"2020/04/13/Python-learning-3/","link":"","permalink":"http://yoursite.com/2020/04/13/Python-learning-3/","excerpt":"","text":"今天我们继续学习Python。 9、logs.py 搜索指定目录下所有*.log文件，并压缩以日期格式转储。 在做这个practice之前，我先花半小时的时间了解 log 文件是什么，干什么用的，然后python如何生成log 文件等。 import logging LOG_FORMAT = “%(asctime)s - %(levelname)s - %(message)s”logging.basicConfig(filename=’my.log’, level=logging.DEBUG, format=LOG_FORMAT)logging.log(logging.DEBUG, “This is a debug log.”)logging.log(logging.INFO, “This is a info log.”)logging.log(logging.WARNING, “This is a warning log.”)logging.log(logging.ERROR, “This is a error log.”)logging.log(logging.CRITICAL, “This is a critical log.”) log 文件是在给实际程序运行时，记录一些重要报错信息，然后程序员可以根据log file提供的信息修正程序，大批量时候甚至可以分析用户的行为。 弄清楚logfile 之后，开始看这个代码怎么写。首先，使用os.listdir把对应文件中文件提取，然后使用files.endswith 抓出相应结尾的文件如果.log，最后使用zipfile 将对应文件zip起来： import os # Load the Library Moduleimport zipfile zip = zipfile.ZipFile(‘log.zip’,’w’)logsdir = “/Users/Yu/Desktop” # Set the Variable logsdir for files in os.listdir(logsdir): # Find all the files in the directory if files.endswith(“.log”): # Check to ensure the files in the directory end in .log zip.write(files) 10、move_files_over_x_days.py 移动所有满足指定时间日期的文件从源目录到目标文件。 import osimport shutilimport time dst = ‘/Users/Yu/Desktop/Move_files’src =’/Users/Yu/Desktop’now = time.time()days = 365if not os.path.exists(dst): os.mkdir(dst) for f in os.listdir(src): # Loop through all the files in the source directory if os.stat(f).st_mtime &lt; now - days * 86400: # Work out how old they are, if they are older than 365 days old if os.path.isfile(f): # Check it’s a file shutil.move(f, dst) # Move the files上述代码考察了 shutil, time 的使用。先用 listdir找出所有文件，然后filter 出上次修改时间大于xx天的文件，os.stat(f).st_mtime,然后用 shutil.move移动相应文件。 To be continue…","categories":[],"tags":[]},{"title":"邻里纠纷水管维修记","slug":"邻里纠纷水管维修记","date":"2020-04-12T13:10:55.000Z","updated":"2020-04-12T14:13:37.984Z","comments":true,"path":"2020/04/12/邻里纠纷水管维修记/","link":"","permalink":"http://yoursite.com/2020/04/12/%E9%82%BB%E9%87%8C%E7%BA%A0%E7%BA%B7%E6%B0%B4%E7%AE%A1%E7%BB%B4%E4%BF%AE%E8%AE%B0/","excerpt":"","text":"这是一个很长的故事。去年底开始，我家客厅的墙壁开始起霉斑，然后墙面的石灰开始泛出，初步判断是漏水了。经过和物业调查，发现是隔壁室内卫生间墙壁水管出现漏水状态，同时由于墙面老旧没有正常防水等原因，导致隔壁卫生间的水漏到我家里来。我和隔壁房东联系了，一开始该房东态度还比较积极，说是会来处理。可是后来，每周给他电话询问何时来的时候，他总是推托，大意是要和他爸商量。等了1个多月后，我实在没有办法，于是我到小区的居委会将此事申述。一开始，我以为居委会并不会帮忙做什么，大概就是来看下，打个电话了解沟通一下。我此前对居委会的印象和感觉其实一直不好，感激这是官方办的一个组织，但实际并不会做太多工作，再加上之前办户口和另外一个小区居委会打交道时，当时我没有很好的体验。所以一直以来，我觉得我能够自己沟通解决就尽量自己解决。但这次我实在没办法了，就抱着先把事情投诉给居委试试看的想法。 后来发生的事情，让我大大没想到，同时对居委也充满了感激。当天我上报我的漏水情况后，居委马上派了两个干部来到我家了解情况。他们先是到我家看了漏水情况，然后询问漏水多久了和是否已经同隔壁房东沟通过等。隔壁房间是隔壁房东租出去的，那天下午租客不在家。于是当天晚上，居委联系物业又再来了一次，待租客在家后，我们再一起到隔壁卫生间查看漏水问题。判断和上次一样，水管漏水。居委了解到我们和隔壁房东屡次沟通无果后，他们说他们会主动来协调。 中间由于新冠疫情原因，这个事情耽搁了2个月。我的房间墙面开始脱皮，石灰开始掉落。就在2周前，我和居委沟通，然后他们也很理解我，于是决定当防疫降到2级响应后，马上帮我联系协调。一开始，隔壁房东也是说会来维修，但是过了两周还是没有来，同时电话中还说这个漏水同他没有关系。最终，居委帮忙施压，同时和我说如果未来打官司，他们可以为这个事情作证。几经沟通后，隔壁房东昨天终于带人来维修了。居委的人也提前和我协调好，他们派出两个干部，小区片警察（真警察，不是协警）和物业前来沟通。一开始，隔壁房东还是说，不是他的问题，跟他没关系，在了解情况和打开墙面观察后，隔壁水管的确有漏水。隔壁房东答应维修。但是不答应对我家做出赔偿。然后我强调，我已经在11月底明确通知，但隔壁房东并没有积极主动配合解决，无视我的财产安全，中间由于疫情拖了那么久，隔壁房东需要为他的行为负责。居委和警察帮忙积极协调，同时也跟我说，如果对方不答应，可以到法院申诉，受理7日内有结果。鼓励我如果不行就通过法律手段解决。双方摊牌后，隔壁房东也没有原来那么硬气了。同时也答应赔款私聊。在居委和警察的协调下起草了协议书，全赔我的墙面损失，同时修缮好他自己家的卫生间水管问题。 这次事情，非常感谢我们小区的居委做出的努力和帮助。同时在协调过程中，据理力争，为我的合法权益得到了保护，同时我觉得真的伸张了社区正义，构建和谐社会和建设精神文明社区做了有力工作。事情最终没有闹到法院，居委的行动帮助了我维护好了我的财产安全。明确告知隔壁房东的行为是错误的。 本文毫无政治关系或政治正确嫌疑，作为一个普通市民，说一声：感谢国家，感谢党。感恩！","categories":[],"tags":[]},{"title":"Python - learning -2","slug":"Python-learning-2","date":"2020-04-12T08:21:26.000Z","updated":"2020-04-12T13:08:23.766Z","comments":true,"path":"2020/04/12/Python-learning-2/","link":"","permalink":"http://yoursite.com/2020/04/12/Python-learning-2/","excerpt":"","text":"今天我们继续Python 的 学习。 5.dir_test.py 检查目录 testdir 是否存在, 如果不存在则创建一个。这个practice 有点和前面第二个相似，主要是考察 os.path 的用法。其中有两个重要的module分别是 os.path.exists 和 os.makedirs 后一个主要是生成新的目录。 、、、import os CheckDir = input(“Enter the name of the directory to check : “)if os.path.exists(CheckDir): # Checks if the dir exists print(“The directory exists”)else: print(“No directory found for “ + CheckDir) # Output if no directory os.makedirs(CheckDir) # Creates a new dir for the given name print(“Directory created for “ + CheckDir)、、、 6、env_check.py 检查环境变量 这个practice 我有点没懂意图，我搜索了一下，有说python其实没什么特殊变量仅仅需要将python放入path中确保后面可以调用。这个先放一下把，继续下一个。 7、fileinfo.py 展示文件的元信息 这个 practice 我理解 主要是考察 os.stat 的用法，通过这个module 可以直接查看file的一些信息。、、、import osimport stat # index constants for os.stat()import sysimport time def fileinfo(file_name): file_stats = os.stat(file_name) # create a dictionary to hold file info file_info = { ‘fname’: file_name, ‘fsize’: file_stats[stat.ST_SIZE], ‘f_lm’: time.strftime(“%d/%m/%Y %I:%M:%S %p”, time.localtime(file_stats[stat.ST_MTIME])), ‘f_la’: time.strftime(“%d/%m/%Y %I:%M:%S %p”, time.localtime(file_stats[stat.ST_ATIME])), ‘f_ct’: time.strftime(“%d/%m/%Y %I:%M:%S %p”, time.localtime(file_stats[stat.ST_CTIME])), # ‘no_of_lines’: count, # ‘t_char’: t_char } # print out the file info file_info_keys = (‘file name’, ‘file size’, ‘last modified’, ‘last accessed’, ‘creation time’, ‘Total number of lines are’, ‘Total number of characters are’) file_info_vales = (file_info[‘fname’], str(file_info[‘fsize’]) + “ bytes”, file_info[‘f_lm’], file_info[‘f_la’], file_info[‘f_ct’]) for f_key, f_value in zip(file_info_keys, file_info_vales): print(f_key, &apos; =&apos;, f_value)fileinfo(‘vgsales.csv’)、、、 8、folder_size.py 统计当前当前文件夹的大小： 这里主要考察的是 如何获取文件size 大小，然后在累加得出整个folder size 大小。其实获得文件size大小有两种方法：os.path.getsize(filepath) 或者 os.stat(filename).st_size。然后再通过处以1024的转换得到MB or GB，原本得到的file size 是以 KB为单位。同时 os.walk 和 os.path.join 也是非常重要的module。 import osimport sys def get_folder_size(start_path): total_size = 0 for (path, dirs, files) in os.walk(start_path): # Walk through all the directories. For each iteration, os.walk returns the folders, subfolders and files in the dir. for file in files: # Get all the files filename = os.path.join(path, file) total_size += os.path.getsize(filename) return total_size 但是我编写的上面这段代码，抓出来的folder size 大小和实际电脑前面看到的 有 1-3 MB 的差距。也不知道为什么。 To be continue…","categories":[],"tags":[]},{"title":"Python - learning -1","slug":"Python-learning-1","date":"2020-04-05T09:21:17.000Z","updated":"2020-04-05T15:23:47.607Z","comments":true,"path":"2020/04/05/Python-learning-1/","link":"","permalink":"http://yoursite.com/2020/04/05/Python-learning-1/","excerpt":"","text":"最近开始学习Python，进步比较慢。我已经把基础课程都学习完了。感觉可以开始上手项目了。后来发现，其实根本不是这样。于是开始搜索了31一个python小例子。由于学习内容比较杂乱，经常是这个学习完了，就忘了那个。我现在想想，关键是没有总结和记录，当天找到的solution，回头过几天就忘记了。所以决定开文章来记录具体学习了什么。如下代码全是操的，我发现我其实根部就没过基础这关。了解下面代码就已经很花时间了。 batch_file_rename.py 批量重命名指定目录下面所有文件的后缀名。import os def batch_rename(work_dir, old_ext, new_ext): os.chdir(work_dir) for filename in os.listdir(work_dir): Get the file extension split_file = filename.split(&apos;.&apos;) if old_ext == split_file[-1]: new_name = split_file[0] +&apos;.&apos;+new_ext os.rename(filename,new_name) batch_rename(‘/Users/Yu/Desktop/Python_Practice’,’txt’,’py’) 上面这个例子，第一次知道 可以 import os，然后 python 可以后计算机进行互动。当中有些重要的小function，os.chdir, os.rename,os.path.join create_dir_if_not_there.py 如果不存在的目录。 import os home = os.path.expanduser(“~”)print(home) if not os.path.exists(os.path.join(home, TESTDIR)): os.makedirs(os.path.join(home, TESTDIR))这里的知识点，主要还是 对于 os 的使用。比如 os.makedirs,os.path.exists,os.path.expanduser 3.Fast Youtube Downloader 多线程高速下载Youtube视频 这个case 刚开始看答案的时候，一头雾水。仔细搜索后才知道 youtube-dl 和 aria2 的使用。但是关于 multi-thread的用法还是没有理解，我决定先再放一放继续下面的项目。在 这个项目中需要先安装youtube-dl 和 aria2 之后才能使用，同时由于网路原因直接 terminal下载时有些问题。 youtube-dl video_link –external-downloader aria2c –external-downloader-args -x ‘2’但使用下面这个 code 可以正常加速下载： import subprocessimport sys video_link, threads = sys.argv[1], sys.argv[2]subprocess.call([ “youtube-dl”, video_link, “–external-downloader”, “aria2c”, “–external-downloader-args”, “-x” + threads]) 在学习这个过程中，我还知道 能够使用aria2 下载 磁力链接 和 普通下载链接的方法，我都亲自试了一下，但感谢下载速度也一般啊。$ aria2c http://example.org/mylinux.iso$ aria2c http://example.org/mylinux.torrent$ aria2c ‘magnet:?xt=urn:btih:248D0A1CD08284299DE78D5C1ED359BB46717D8C’$ aria2c http://example.org/mylinux.metalink$ aria2c -i uris.txt Google Image Downloader 根据指定词语从Google搜索图片并下载。拿到这个例子后，我一点头绪都没有，首先先去谷歌搜索了一下。刚一搜索，我去，有人已经编写好这个module了，理论上来说，我只要pip install 这个 model，就可以 直接调用module 下载Google 图片了。我到了 module 这个 github 页面看了一下，1000多行 code，叫我自己编，是不可能编出来的。 pip3 install google_images_downloadgoogleimagesdownload -k “python” -l 20 -k 代表 关键词，后面跟要搜索的内容，-l 后面跟要下载的数量。一开始我觉得太简单了，后来出现报错。我以为是我操作有问题，但这么简单怎么会有问题。一开始我是觉得需要下载一个Chromedriver, 但后来发现其实不是。于是，我仔细调查了一下，发现，谷歌修改了 image format 后，使用同样 module 是无法下载了。经过一番search，参照GitHub上面大神修改源代码后，成功下载图片。但是据说limit 100 的情况无法解决。下载图片数量需要少于100，同时我看还是会有些图片format原因无法下载。 googleimagesdownload -k ‘Julia’ -l 5 –chromedriver=”./chromedriver” 总之，勉强使用这个module成功下载了图片。 To be continue…","categories":[],"tags":[]},{"title":"最近很多新闻报道和股市的看法","slug":"最近很多新闻报道和股市的看法","date":"2020-02-29T09:14:33.000Z","updated":"2020-02-29T11:08:04.259Z","comments":true,"path":"2020/02/29/最近很多新闻报道和股市的看法/","link":"","permalink":"http://yoursite.com/2020/02/29/%E6%9C%80%E8%BF%91%E5%BE%88%E5%A4%9A%E6%96%B0%E9%97%BB%E6%8A%A5%E9%81%93%E5%92%8C%E8%82%A1%E5%B8%82%E7%9A%84%E7%9C%8B%E6%B3%95/","excerpt":"","text":"#股票我记得在上周包括上周的周末，无数的利好消息铺天盖地而来。A股不会再低过3000点，银行降息，央行大放水，北上外资流入。首先这个北上资金就根本不是什么外资，他是国企的海外公司换汇后进入中国回购股票的。这个事情其实很有意思，你们都说香港不重要了，不要 care 香港怎么的怎么的。外资涌入中国，现在唯一途径和口岸只有香港，上海不行。因为体制和法制的不同。以上海现有的情况，很难成为国际化金融大都市，因为法律不同，外资并不允许在上海自由出进。理想很美好，现实不允许。所以其实北上资金某种程度还是内部资金，另外香港很重要。说外资看好中国，央企政策支持云云后，这周开始跌，然后昨天大跌，我2017年入股以来我经历的最大跌幅。我上周六看到媒体的消息和股票小手进入笔数这么高，我就知道大盘要跌了。媒体释放假消息，叫散户进去接盘，为什么没人能提醒散户要警惕。为什么我们国家没有不同的声音，而只是一个统一的声音。 #国际疫情最近这周开始韩国，日本，美国和意大利等国都出现了新冠疫情。然后媒体又是普天报道，韩国防控不力，美国防控不力，日本做假数据，意大利反应迟钝。同时大肆宣传，中国防控及时，效果非常好而且反应迅速。就让我觉得有种，刻意宣扬其实国外也一样，我们系统没问题一样。我非常非常反对这这种做法。我们还是应该好好讨论过去一个月，究竟发生了什么，我们未来可以怎么做。不是说中央组进驻武汉调查李文亮事件，其实也有些时日，但是并没有听到消息或任何调查结果。至于道歉就更遥遥无期了。我个人看法觉得，我们国家其实是建立了一套标准流程和体制的，根据流程李文亮的确是应该被抓起来当作传谣者，调查结果应该是人民警察的确也根据流程办事，没法说他们做错了。如果要进行道歉，那未来真的有传谣者如何把控。及早制定言论机制比较妥当，法律规定什么可以说，什么可以讨论，什么不能说，让更多的信息透明化，我觉得这是比较好的方法。不应该再把人民群众当成愚蠢的人民，相信人民有自己的判断力。这不，美国最近也有人在 Youtube 上号称美国感染人数已经超过1000人，但是美国有人去把他当作传谣者了吗？他被警察抓起来了吗？ 再说韩国，我就不知道我们媒体什么脑子，说要警惕国外人大批流入中国。首先从韩国回来的都是中国人，你们多去教育一下他们才是，都是自己同胞，按理也应该接纳。其次，如果作为一个外国人，去到别的国家，人生地不熟，语言又不通，对方国家医疗水平也不知道怎么样。这个情况下，换做是你，你会跑到国外避难吗？以平均智商来说，不可能啊，待在家里和本国是最好选择。所以机票炒起来是被在韩国的中国人炒起来的，不是韩国本地人炒起来的。而且我还算是了解韩国人的，在他们心里，中国远远不如韩国，中国不值得他们逃难过来。今天看了一个韩国本地人在youtube做的vlog，按她来说韩国政府和民众还是挺重视的，应对安排得也很不错。我就不知道，中国媒体为什么乱引流，让大家觉得国外也一样。本国自己的问题不多报道，不多探讨，倒是很热衷国外的问题。 #孙扬禁赛对现在中国的舆论环境，我真是火大。宣判之前，国内媒体报道，基本论调就是孙扬应该是稳的，对方程序不正义，采集药监人员没有合格资质。为什么这次判决出来，是禁赛8年。为什么当初媒体没有引导理性讨论的声音，而是一边倒的无脑支持孙扬。好了，现在统一打脸，然后下面评论就开始带风气,例如美国也吃药，澳洲人也吃药云云。游戏规则人家制定的，不愿意玩就别玩，玩输了就大方认输。要么就增加话语权，修改规则。按中国媒体这调性，十分担心培养出来的我国人民，是否真的有独立思考的能力，是否真的能有自己判断的能力，如何为未来的民主选举做准备啊。还有中国足球，搞得都像是世界十大未解之谜。这个问题有这么复杂吗。中国足球主要两个问题：1. 以前领导重视不够，因为这个运动需要职业化，如果你是体育总局长，你的kpi 是奥运或世界运动会拿了多少金牌，我乒乓球培养一个人拿一枚金牌，我足球培养十一个人也是拿一枚金牌，那当然是放弃集体项目。2. 足球运动是一个商业化和职业化的运动。为什么女排女足成绩好，因为女性运动职业化不够普及，粗犷来说，就是拼人种。但是男性运动就不同，职业化普及，各方面和体系完备。这个不是抓几个人训练就训练得出来的。再加上足协主席不是专业人，就更不懂这些了。这种问题不难探讨清楚，但是媒体并不报道，也不敢报道。媒体一味的引导畸形的社会看法，一味的对外拉仇恨，然而我们和社会对自身的问题并没有足够认识。2003年非典后，我们学到了什么。2020年感染人数8万，死亡人数逼近3000，武汉地区死亡率超过非典时期。天天反思，天天努力，但中国足球的成绩就是起不来，而且越来越差。有没有点中国足球内味儿了。","categories":[],"tags":[]},{"title":"及时的得到有用的信息反馈，是提高政府工作的保障","slug":"及时的得到有用的信息反馈，是提高政府工作的保障","date":"2020-02-12T16:20:36.000Z","updated":"2020-02-12T16:45:16.534Z","comments":true,"path":"2020/02/13/及时的得到有用的信息反馈，是提高政府工作的保障/","link":"","permalink":"http://yoursite.com/2020/02/13/%E5%8F%8A%E6%97%B6%E7%9A%84%E5%BE%97%E5%88%B0%E6%9C%89%E7%94%A8%E7%9A%84%E4%BF%A1%E6%81%AF%E5%8F%8D%E9%A6%88%EF%BC%8C%E6%98%AF%E6%8F%90%E9%AB%98%E6%94%BF%E5%BA%9C%E5%B7%A5%E4%BD%9C%E7%9A%84%E4%BF%9D%E9%9A%9C/","excerpt":"","text":"今晚看了一个视频，讲述武汉市市区司机运送病人到雷神医院，由于组织混乱，导致司机从早忙到晚，到了医院也不知道把病人送到哪里。看到这里，我觉得大家都很气愤。视频放在这里。 我觉得主要的原因是，我们的政府官员长期没有得到有益的反馈，导致算法非常粗暴简单。我们都知道，人工智能需要海量的数据来计算出优质的模型，从而得到最优化的策略。人和一个组织也是如此。我们都知道孟母三迁的故事，知道家长操心学区房的故事，知道花大价钱去读好学校的故事。所有的这些，都是未来小孩能在一个好的环境成长，环境给到孩子的是优质教育资源的教导，这些教导其实就转化成数据传回给孩子，于是每个人的算法就有了不同。未来每个人遇到事情的选择就不同，所以大部分教育背景好的孩子，能够计算出比较优的策略来做出选择。 我们的组织和政府也是如此。如果每天拿到的数据很单一，就没有办法得到最优化的解决方案。因为你的算法跟不上。但是很遗憾的事，目前我们的环境更多的是歌颂我们做的事情多么的成功，而不是全方位的去抓取数据来分析处理。所以，这样的组织，在算法上就会有严重的缺陷。我在工作中，前几天还和team里面的人讨论，他们的想法是，树立榜样机制，让大家都看到这个好榜样，大家都学习这个榜样，这样我们team 的工作成绩就会越来越好。我个人不完全认同。树立好榜样是好的，但是数据不够完全。具体给到个人，不能光给积极的反馈，获取数据需要全方位的，如果单一树立好榜样，并不能要我们的组织能够获得最优算法，从而做出最好的策略选择。换之，我们目前政府的情况也是如此。更糟糕的是，给出其它反馈的人都被404了。 所以，我们看到了视频中，安排混乱的情况。再看武汉这几周应对疫情的反应，也可以看出，算法很差。","categories":[],"tags":[]},{"title":"重要的一天，我又能为国家和民族做些什么呢","slug":"重要的一天，我又能为国家和民族做些什么呢","date":"2020-02-07T15:45:16.000Z","updated":"2020-02-07T16:01:58.000Z","comments":true,"path":"2020/02/07/重要的一天，我又能为国家和民族做些什么呢/","link":"","permalink":"http://yoursite.com/2020/02/07/%E9%87%8D%E8%A6%81%E7%9A%84%E4%B8%80%E5%A4%A9%EF%BC%8C%E6%88%91%E5%8F%88%E8%83%BD%E4%B8%BA%E5%9B%BD%E5%AE%B6%E5%92%8C%E6%B0%91%E6%97%8F%E5%81%9A%E4%BA%9B%E4%BB%80%E4%B9%88%E5%91%A2/","excerpt":"","text":"今天凌晨得知一个悲哀的消息，武汉市中心医院李文亮医生不幸逝世。他是第一个喊出冠性肺炎是有人传人的医生，但是喊出这个消息后，被定性为谣言传播者，之后又被辟谣。当我得知这个新闻的时候，我到卫生间速口，杯子不小心抖了一下打到台面。我抖的原因是愤怒和悲哀。同时，今天我更多的感受到了社会的哀鸣。今天中午，新闻播报，中央纪委会派人彻查此事件，中央也意识到这个问题的严重性。希望能换来一个道歉。 今天，在哔哩哔哩看到了up主周扒片新制作的一个视频《【扒】不能哭泣，笑容就毫无意义，这里的人处决亲闺女的时候都要笑。《奇诺之旅》之微笑国》，视频链接在这里：https://www.bilibili.com/video/av87256079?from=search&amp;seid=11042822919759276884 观看影片后有三点感想： 影片映射 批评不自由赞美无意义。反响现实当下国内的环境和处境。 视频中，以奇诺为首的国度，骨子里会看不起女孩的国度。于是会有意识形态的冲突最终上升到战争。 周扒片这个博主是一个运营高手，而且非常应景接地气。这个时候制作这种短片，可以极速吸粉。而且片子有点鲁迅的影子。 晚上有读了一篇对曹德旺的采访，曹先生说，中国是中国人的中国，现在当务之急是先稳定疫情，有什么问题可以后面再慢慢讨论。同时，我也看到中央财政拨款几百亿的拨款，举全国之力救治和支援湖北。国家政府的确也都有在努力，白花花的银子拨款下来。我们又为这个国家和民族做了些什么呢。 写罢，还是去读书和学习读下韩语吧。时刻准备着，有朝一日，民族的召唤，成就伟业。","categories":[],"tags":[]},{"title":"“中国人不相信对不起－武汉人民”","slug":"“中国人不相信对不起－武汉人民”","date":"2020-02-05T13:53:33.000Z","updated":"2020-02-05T14:14:35.000Z","comments":true,"path":"2020/02/05/“中国人不相信对不起－武汉人民”/","link":"","permalink":"http://yoursite.com/2020/02/05/%E2%80%9C%E4%B8%AD%E5%9B%BD%E4%BA%BA%E4%B8%8D%E7%9B%B8%E4%BF%A1%E5%AF%B9%E4%B8%8D%E8%B5%B7%EF%BC%8D%E6%AD%A6%E6%B1%89%E4%BA%BA%E6%B0%91%E2%80%9D/","excerpt":"","text":"最近武汉的疫情，牵动了所有中国人民的心。很多人在喊武汉加油，中国加油。同时，外国的一些不公平的声音和对中国人不公平的评论，以及很多辱华言论，都遭到了大家和国际社会的声讨。对于敏感话题，我觉得我就不多评价了。我始终坚持和支持，播报透明，公平对待每一种声音，如果一开始疫情就能够得到很好的重视，情况不会如此的糟糕。但是事实是，我们没有如果。事情既然已经发生了，我们就需要好好考虑，现在应该怎么办。 这几天，我几乎每天都可以看到我们的新闻和媒体在播报武汉市政府，湖北省政府以及红十字会的道歉采访。一致的发声，大意就是，我们对这次的灾难深感愧疚和自责，我们知道有些工作我们没有做好。每次看到这里，我都不经想起了曾仕强的一句话，大意是中国人不相信对不起，不要对一个中国人说对不起。当时看到他的书时，我不是十分明白这个道理。现在，我认识得很深刻。每天看着湖北和武汉人民的死亡人数不断增加，同时武汉地区的疾病死亡率将近5%，然而非湖北地区的死亡率不到0.5%。面对泉下的那些武汉人民，我们说一句对不起，有用吗？ 今天晚上在家看到一则新闻：https://new.qq.com/omn/20200205/20200205A0LS1E00.html 这真是我第一次看到策略和战术清晰，逻辑有条理的内容报道。从内容报道中，我有感觉得出来，这下有希望了。之前的报道和新闻，我看到的更多是逻辑混乱，没有具体的策略，具体要怎么做也不是十分清楚，感觉很多力量就是一盘散沙。新闻中，有具体分析到，目前感染人数，未来可以有的床位，以及检验试剂盒的数量，每天可以检验多少名病人，若检验出来后如何处理等。我觉得，未来几天疫情战况会非常明亮，周末分胜负。 职位越高，每天更应当如履薄冰，而不是整天创造出什么网络流行用语，紧平衡。事情发生后，整天就是愧疚，愧疚换不回来人民的幸福生活。 湖北人民加油，致敬奋战在一线的工作者们。","categories":[],"tags":[]},{"title":"李连杰的爱情电影精武门","slug":"由李连杰的电影想到","date":"2020-01-05T14:50:16.000Z","updated":"2020-01-05T15:51:34.000Z","comments":true,"path":"2020/01/05/由李连杰的电影想到/","link":"","permalink":"http://yoursite.com/2020/01/05/%E7%94%B1%E6%9D%8E%E8%BF%9E%E6%9D%B0%E7%9A%84%E7%94%B5%E5%BD%B1%E6%83%B3%E5%88%B0/","excerpt":"","text":"前些天在电视上正好看到李连杰的经典电影《精武门》，我突然发现这部电影不单单是打斗场面上很精彩，同时剧本写的也非常优秀，里面体现出的很多道理到今天都非常值得回味和学习。同时里面很多的台词都非常经典。 首先这部电影的爱情片段太经典了，我真是有点怀疑，这哪是武打片，根本就是一部伟大的爱情电影啊。李连杰在法庭准备被判刑，一个日本白富美走了进来，和对方律师说，我是山田光子，我父亲是日本教育部长，我可以证明陈真的不在场，当晚他都和我在一起。说完陈真无罪释放后，陈真问山田光子：你怎么会在这里？光子回答：我现在已经抛弃了一切，你要养我一辈子哦。陈真坚定的点头：嗯。光子开心的笑了。这几个镜头和简单的台词，再加上前面剧情的铺垫，这样爱情的伟大和男人的担当在这部片子表现的淋漓精致，这样的爱情电影暖暖的让人感动，比现在那些什么青春爱情电影强太多了啊。 于是陈真带着光子回到了精武门，让陈真他们没想到的是所有人都对这个日本小姐嗤之以鼻，因为她是一个日本人。后来陈真带着光子出去找旅舍住，但是没有旅舍愿意接待一个日本人，于是陈真只能和光子搬到了郊外的茅草屋住。这里又再一次的见证了这部电影的爱情线刻画得很好。两人顶住巨大压力还是继续走在了一起，然后后面的反转也非常经典。真是淡淡的忧伤。 不过这里我要插播一个感想。时间回到了十几年前，中国著名篮球明星王治郅远赴美国打NBA。王治郅为了希望能在美国NBA联赛有更好的发展，同时也是为了更好的增长自己的球技，于是决定留在美国参加夏季联赛后，在美国等待中国篮球队的到来参加世锦赛。因为此次事件，王治郅被中国整整封杀了4年，期间各种流言蜚语，什么背叛，不爱国，军人的耻辱。仔细回顾事件，以及2006年后王治郅回到国家队的表现，我们都知道，大郅始终是那个郅，那颗赤子之心从未改变。回顾当年，大郅并不是说不参加中国队比赛，而是希望在夏季联赛练级，仅仅因为如此，就被各种抹黑。我觉得中国篮协始终欠大郅一个道歉。 回到精武门，光子小姐的确是一个日本人，但是她只是一个普通的日本人。而且她是一个好人。但是影片中没有人愿意接纳她，包容她。我还是觉得这与当年王治郅的情况类似。我还是觉得有问题，但我有些说不出来。我觉得一个人可以有他的个人选择，但是在中国社会和学习教育中，我们是不接受异类的。老师定义的好就是好，社会定义的好就是好。这种性格和气质，可能不会随着朝代的改变而改变，但我还是希望我们的社会能更开放和包容。反观当年鲁迅去日本求学，鲁迅的导师藤野先生非常关怀鲁迅，为了纪念自己的导师，鲁迅写了篇散文《藤野先生》。未来的中国是 大国和强国，然而现在常常又表现得太敏感和小气了。 后来，陈真和光子住在郊外的茅草屋，客服各种困难生活在一起，这根本就是部爱情片。一天船越先生来找陈真比武，比武多经典我就不说了，但我还想强调里面每句台词都很经典。比武结束后，船越先生说：中国人的武功强调的是个人修为，而不注重实战，年轻人我要告诉你，要击倒对方最好的就是用手枪，练武的目标是要将人体的体能推到最高极限，如果你想达到这种境界，就必须要了解宇宙苍生。 陈真和船越先生的对话，充分的体现了，中国传统武术更讲究的是个人修为，而不是战斗技巧。这让我想起去年传武打架的事件。可能大家都理解错了，我赞同船越先生的说法，中国武术更讲究修为，同时武术里面还包含了很多哲理，哲理中又饱含了宇宙苍生的秘密。经典。现在那些传武看样子也不是读书人，坦白说真正能按下心来读书的几乎没有，就更别期望他们能传给弟子们什么宇宙的秘密了。 回到影片，后来，光子为了陈真离开了中国。在信中写到：对不起，我终于决定还是要走，人生有些事比爱情重要 ，没有我在你身边你能做的事更多了，遵守你的若言，等日本军队回到日本的时候，我会在京都等你。脑中脑补京都樱花的画面，如果电影在此完结，这就是一个凄惨的爱情故事电影。","categories":[],"tags":[]},{"title":"保罗让我想起了谁?","slug":"保罗让我想起了谁","date":"2019-12-18T14:28:12.000Z","updated":"2019-12-18T15:37:29.000Z","comments":true,"path":"2019/12/18/保罗让我想起了谁/","link":"","permalink":"http://yoursite.com/2019/12/18/%E4%BF%9D%E7%BD%97%E8%AE%A9%E6%88%91%E6%83%B3%E8%B5%B7%E4%BA%86%E8%B0%81/","excerpt":"","text":"其实雷霆的比赛已经是昨天发生的了，但是思考来，我今天还是希望提笔mark down一下。昨天看到保罗的新闻后一开始是觉得很猛，然后看了比赛和评论觉得很激励。仔细品味一下，的确很值得倾佩。 试想保罗作为一个全明星控卫，当年的天之骄子，如今联盟的公会主席，怎么着都是为了争冠而生，都是为了争冠而来的。如今保罗已经35岁，从火箭被交易到了鱼腩队雷霆。雷霆今年是怎么都不会有争冠希望的，但保罗的年龄也越来越大，似乎在他职业生涯之前，难求一冠。但是看了他昨天的比赛，我非常振奋，我看到的仍然是那个坚强不屈，有着无限求胜欲望的保罗。看着他第四节一个又一个的投进三分球，我的思绪发生了穿越。 遥想三国时期，刘备创业时期，在公元200年依附刘表时，已经40岁。打拼几十年，事业迟迟未有起色。一直到公元207年，将近50岁的刘备拜访了诸葛亮请孔明出山后，事业才渐渐的有所起色，开始占据地方成为一方霸主最后称帝。 真正的英雄，是在前路漫漫，看不到光明时，仍然保持不屈的斗志不断竞争和努力。 致敬保罗。不到最后一刻绝不能放弃，放弃的话，比赛就在那时提前结束了。一场比赛如此，一个球员的职业生涯如此，人生也是如此。不到最后，谁知道呢，保罗，相信你能最后捧起奥布莱恩杯！","categories":[],"tags":[]},{"title":"我的新博客正式上线啦","slug":"我的新博客正式上线啦","date":"2019-12-16T14:53:32.000Z","updated":"2019-12-16T15:03:46.000Z","comments":true,"path":"2019/12/16/我的新博客正式上线啦/","link":"","permalink":"http://yoursite.com/2019/12/16/%E6%88%91%E7%9A%84%E6%96%B0%E5%8D%9A%E5%AE%A2%E6%AD%A3%E5%BC%8F%E4%B8%8A%E7%BA%BF%E5%95%A6/","excerpt":"","text":"第一章晚上11点，发出第一篇文章。首先感想是愿世界和平。刚在纽约时报浏览了俄罗斯车臣战争的图片，随后想起香港的骚乱，然后试想未来或许发生的台海战争。总结，希望国家和社会稳定，世界和平。 第二章内容 参考文献https://cn.nytimes.com/slideshow/20191213/c13Chechen-ss/#1","categories":[],"tags":[]},{"title":"a","slug":"a","date":"2019-12-15T15:00:59.000Z","updated":"2019-12-15T15:02:21.000Z","comments":true,"path":"2019/12/15/a/","link":"","permalink":"http://yoursite.com/2019/12/15/a/","excerpt":"","text":"Some content","categories":[],"tags":[]},{"title":"Hello World","slug":"hello-world","date":"2019-12-15T11:01:20.000Z","updated":"2019-12-15T14:59:30.000Z","comments":true,"path":"2019/12/15/hello-world/","link":"","permalink":"http://yoursite.com/2019/12/15/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}]}